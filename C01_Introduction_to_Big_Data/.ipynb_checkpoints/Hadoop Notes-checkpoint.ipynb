{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hadoop Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error: copyFromLocal: `.': No such file or directory:......\n",
    "\n",
    "Solution: hdfs dfs -mkdir -p .\n",
    "\n",
    "find / -name hadoop-mapreduce-examples*.jar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hadoop Examples Command:\n",
    "hadoop jar /usr/local/Cellar/hadoop/3.1.1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar\n",
    "\n",
    "\n",
    "aggregatewordcount: An Aggregate based map/reduce program that counts the words in the input files.\n",
    "\n",
    "\n",
    "  aggregatewordhist: An Aggregate based map/reduce program that computes the histogram of the words in the input files.\n",
    "  \n",
    "  \n",
    "  bbp: A map/reduce program that uses Bailey-Borwein-Plouffe to compute exact digits of Pi.\n",
    "  \n",
    "  \n",
    "  dbcount: An example job that count the pageview counts from a database.\n",
    "  \n",
    "  \n",
    "  distbbp: A map/reduce program that uses a BBP-type formula to compute exact bits of Pi.\n",
    "  \n",
    "  \n",
    "  grep: A map/reduce program that counts the matches of a regex in the input.\n",
    "  \n",
    "  \n",
    "  join: A job that effects a join over sorted, equally partitioned datasets\n",
    "  multifilewc: A job that counts words from several files.\n",
    "  \n",
    "  \n",
    "  pentomino: A map/reduce tile laying program to find solutions to pentomino problems.\n",
    "  \n",
    "  \n",
    "  pi: A map/reduce program that estimates Pi using a quasi-Monte Carlo method.\n",
    "  \n",
    "  \n",
    "  randomtextwriter: A map/reduce program that writes 10GB of random textual data per node.\n",
    "  \n",
    "  \n",
    "  randomwriter: A map/reduce program that writes 10GB of random data per node.\n",
    "  \n",
    "  \n",
    "  secondarysort: An example defining a secondary sort to the reduce.\n",
    "  \n",
    "  \n",
    "  sort: A map/reduce program that sorts the data written by the random writer.\n",
    "  \n",
    "  \n",
    "  sudoku: A sudoku solver.\n",
    "  \n",
    "  \n",
    "  teragen: Generate data for the terasort\n",
    "  \n",
    "  \n",
    "  terasort: Run the terasort\n",
    "  \n",
    "  \n",
    "  teravalidate: Checking results of terasort\n",
    "  \n",
    "  \n",
    "  wordcount: A map/reduce program that counts the words in the input files.\n",
    "  \n",
    "  \n",
    "  wordmean: A map/reduce program that counts the average length of the words in the input files.\n",
    "  \n",
    "  \n",
    "  wordmedian: A map/reduce program that counts the median length of the words in the input files.\n",
    "  \n",
    "  \n",
    "  wordstandarddeviation: A map/reduce program that counts the standard deviation of the length of the w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
